# ğŸ“°Â LLMâ€‘PDFâ€‘Explorer

*Upload any PDF, ask questions, get answers â€“ all in your browser.*

A Streamlit webâ€‘app that turns PDFs into a searchable knowledge base with **OpenAI embeddings**, **GPTâ€‘4o** and a local **Chroma** vector store.

---

## âœ¨Â Features

| Capability                | Details                                                                                         |
| ------------------------- | ----------------------------------------------------------------------------------------------- |
| **Oneâ€‘click upload**      | Dragâ€‘andâ€‘drop a PDF â€“ pages are textâ€‘extracted, chunked and embedded.                           |
| **Fast semantic search**  | Embeddings are cached in a local DuckDB/Parquet database via Chromaâ€™s new **PersistentClient**. |
| **Naturalâ€‘language Q\&A** | Topâ€‘k relevant chunks are fed to GPTâ€‘4o to generate grounded answers.                           |
| **Perâ€‘session API keys**  | Each visitor can paste their own OpenAI key (supports user or projectâ€‘scoped keys).             |
| **Selfâ€‘healing DB**       | Corrupt stores autoâ€‘wipe and rebuild; zero manual migration pain.                               |
| **Dockerâ€‘ready**          | Singleâ€‘stage `Dockerfile` builds a lean image (\~200Â MB) pinned to PythonÂ 3.11.                 |

---

## ğŸš€Â Quick start

### 1Â Â Clone & set up

```bash
git clone https://github.com/stu2454/llm-pdf-explorer.git
cd llm-pdf-explorer
python3.11 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

### 2Â Â Add your OpenAI credentials

Create **`.env`** in the repo root:

```env
OPENAI_API_KEY=sk-â€¦               # required
OPENAI_PROJECT_ID=proj_â€¦          # only if using an sk-proj key
```

> `.env` is already in `.gitignore` â€“ your secret stays local.

### 3Â Â Run

```bash
streamlit run streamlit_app.py
# then visit http://localhost:8501
```

Upload a PDF, paste a key in **âš™ï¸Â Settings**, and start querying.

---

## ğŸ³Â Docker

```bash
# build
docker build -t llm-pdf-explorer .

# run with env file
docker run -p 8501:8501 --env-file .env llm-pdf-explorer
```

Mount the `db/` folder as a volume if you want embeddings to persist:

```bash
docker run -p 8501:8501 -v $(pwd)/db:/app/db --env-file .env llm-pdf-explorer
```

---

## ğŸ› ï¸Â Architecture in 60Â sec

```
PDF â†’ PyPDF â†’ LangChain chunk splitter
        â†“
  OpenAIEmbeddings (text-embeddingâ€‘3â€‘small) â†’ Chroma PersistentClient (DuckDB)
        â†“                                             â†‘
   GPTâ€‘4o (chat completion) â† topâ€‘k similarity searchâ€”â”˜
```

* **Embeddings dimension**:Â 1â€¯536â€ƒÂ *Collections are created with the correct dimensionality; the app refuses mismatched dims.*
* **Chunk size / overlap**:Â 512Â /Â 64 tokens (tweak in `functions.py`).
* **Database path**:Â `./db` â€“ delete it to start fresh.

---

## ğŸ“Â Roadmap / ideas

* ğŸ”’Â **Auth proxy** so each user requests with their own IP â€¢
* ğŸ”Â OCR pass for scanned PDFs â€¢
* ğŸ–¼ï¸Â Inline image captioning for figures â€¢
* ğŸ“ŠÂ Autoâ€‘detect tables and render as DataFrames.

Contributions & ideas welcome â€“ open an issue or PR!

---

## ğŸ§‘â€âš–ï¸Â Licence

MIT.  Â©Â 2025Â StuÂ Smith.  Use freely, credit appreciated.

